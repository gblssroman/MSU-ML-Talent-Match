{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7723773,"sourceType":"datasetVersion","datasetId":4512102},{"sourceId":7752146,"sourceType":"datasetVersion","datasetId":4532568}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-04T21:33:08.722134Z","iopub.execute_input":"2024-03-04T21:33:08.722806Z","iopub.status.idle":"2024-03-04T21:33:09.200482Z","shell.execute_reply.started":"2024-03-04T21:33:08.722763Z","shell.execute_reply":"2024-03-04T21:33:09.199362Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cosinesim-ft-talent-v1/COSINESIM_FINETUNE_DATASET_16k_final.csv\n/kaggle/input/ml-talent-hack-parsedtrain/output.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## **paraphrase-multilingual-mpnet-base-v2 (Multilingual XLM-roBERTa) FINE-TUNING v2**","metadata":{}},{"cell_type":"markdown","source":"# Here, we assume our dataset for fine-tuning is fully ready (text corpuses are preproccessed, cosine similarity is calcluated):","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cosinesim-ft-talent-v1/COSINESIM_FINETUNE_DATASET_16k_final.csv')\ndf.sample(3)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:09.202245Z","iopub.execute_input":"2024-03-04T21:33:09.202698Z","iopub.status.idle":"2024-03-04T21:33:14.271036Z","shell.execute_reply.started":"2024-03-04T21:33:09.202669Z","shell.execute_reply":"2024-03-04T21:33:14.269957Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                              CONCATED_x  \\\n9016   ЗП: 140000 руб.. Ищет работу на должность:: Пр...   \n2780   ЗП: 139999 руб.. Ищет работу на должность:: Пр...   \n15689  ЗП: 100000 руб.. Ищет работу на должность:: Ру...   \n\n                                              CONCATED_y  COSINE_SIM  \n9016   title: Директор филиала в Екатеринбург. salary...    0.495071  \n2780   title: Ведущий маркетолог Шоу бар, Спа. salary...    0.495395  \n15689  title: DevOps инженер. salary: з/п не указана....    0.596939  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CONCATED_x</th>\n      <th>CONCATED_y</th>\n      <th>COSINE_SIM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9016</th>\n      <td>ЗП: 140000 руб.. Ищет работу на должность:: Пр...</td>\n      <td>title: Директор филиала в Екатеринбург. salary...</td>\n      <td>0.495071</td>\n    </tr>\n    <tr>\n      <th>2780</th>\n      <td>ЗП: 139999 руб.. Ищет работу на должность:: Пр...</td>\n      <td>title: Ведущий маркетолог Шоу бар, Спа. salary...</td>\n      <td>0.495395</td>\n    </tr>\n    <tr>\n      <th>15689</th>\n      <td>ЗП: 100000 руб.. Ищет работу на должность:: Ру...</td>\n      <td>title: DevOps инженер. salary: з/п не указана....</td>\n      <td>0.596939</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Let's import and initialize everything we need:","metadata":{}},{"cell_type":"code","source":"# !pip install sentence-transformers NO NEED TO IN OUR CASE (we've written everything on clean PyTorch)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:14.272215Z","iopub.execute_input":"2024-03-04T21:33:14.272506Z","iopub.status.idle":"2024-03-04T21:33:14.277519Z","shell.execute_reply.started":"2024-03-04T21:33:14.272481Z","shell.execute_reply":"2024-03-04T21:33:14.276397Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\n# from sentence_transformers.losses import ContrastiveLoss\n# from sentence_transformers import SentenceTransformer\nimport torch\nimport torch.nn as nn\n\nmodel = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\ntokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n\n#for clean PyTorch this can be used:\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] \n    #as it contains all embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    #att mask size -> token embs size\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    #paddings to zero\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    #normalization excluding zero\n    \n    return sum_embeddings / sum_mask #returning avg\n\n#for simplicity let's use one already incl. pooling\n# model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:14.280403Z","iopub.execute_input":"2024-03-04T21:33:14.281314Z","iopub.status.idle":"2024-03-04T21:33:31.926165Z","shell.execute_reply.started":"2024-03-04T21:33:14.281283Z","shell.execute_reply":"2024-03-04T21:33:31.925323Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2eafe4e33a843be933fa3366d8e5e8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b718a9307b5b45349de0771c59d684f8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f4766967394eb2a829e9d5622881c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d887cb7d8e4a434fa1cc3359840c6fb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13282a4fe11f44f0a570edbc55c70ec3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08a489551e0942d58a2697ff5de9d5ba"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Case without splitting texts into corpuses as we will fine-tune on the full corpus data embeddings' similarity with dropping several columns (check README for reference):","metadata":{}},{"cell_type":"code","source":"val_data = pd.read_csv('/kaggle/input/ml-talent-hack-parsedtrain/output.csv')\ncols = list(np.array(val_data.columns))\nprint(cols)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:31.927455Z","iopub.execute_input":"2024-03-04T21:33:31.928122Z","iopub.status.idle":"2024-03-04T21:33:32.034747Z","shell.execute_reply.started":"2024-03-04T21:33:31.928071Z","shell.execute_reply":"2024-03-04T21:33:32.033662Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['Vacancy UUID', 'Vacancy Name', 'Keywords', 'Description', 'Comment', 'Resume UUID', 'First Name', 'Last Name', 'Birth Date', 'Country', 'City', 'About', 'Key Skills', 'Starts', 'Ends', 'Employer', 'Experience City', 'Position', 'Experience Description', 'Year', 'Organization', 'Faculty', 'Specialty', 'Result', 'Education Type', 'Education Level', 'Target']\n","output_type":"stream"}]},{"cell_type":"code","source":"cols_drop1 = cols[0:9] + cols[13:16] + [cols[19]] + [cols[-1]]\nresumes_val = val_data.drop(columns=cols_drop1)\nvac_val = val_data.iloc[:, 1:5]\nlabels_val = np.array(pd.get_dummies(val_data.iloc[:, -1]).astype(int).drop(columns='failed'))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:32.035924Z","iopub.execute_input":"2024-03-04T21:33:32.036240Z","iopub.status.idle":"2024-03-04T21:33:32.052374Z","shell.execute_reply.started":"2024-03-04T21:33:32.036213Z","shell.execute_reply":"2024-03-04T21:33:32.051111Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"resumes_val_text = []\nfor i in range(len(resumes_val)):\n    curr_str = \"\"\n    for j in range(len(resumes_val.columns)):\n        if not pd.isna(resumes_val.iloc[i, j]):\n            curr_str += str(resumes_val.iloc[i, j]) + \". \"\n    resumes_val_text.append(curr_str)\nvac_val_text = []\nfor i in range(len(vac_val)):\n    curr_str = \"\"\n    for j in range(len(vac_val.columns)):\n        if not pd.isna(vac_val.iloc[i, j]):\n            curr_str += str(vac_val.iloc[i, j]) + \". \"\n    vac_val_text.append(curr_str)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:32.053525Z","iopub.execute_input":"2024-03-04T21:33:32.053872Z","iopub.status.idle":"2024-03-04T21:33:32.719823Z","shell.execute_reply.started":"2024-03-04T21:33:32.053846Z","shell.execute_reply":"2024-03-04T21:33:32.719052Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(vac_val_text), len(resumes_val_text), len(labels_val)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:32.720824Z","iopub.execute_input":"2024-03-04T21:33:32.721086Z","iopub.status.idle":"2024-03-04T21:33:32.727908Z","shell.execute_reply.started":"2024-03-04T21:33:32.721063Z","shell.execute_reply":"2024-03-04T21:33:32.726916Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(656, 656, 656)"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass DuoDataset(Dataset):\n    def __init__(self, text1, text2, labels=None):\n        self.text1 = np.array(text1)\n        self.text2 = np.array(text2)\n        if len(labels) > 0:\n            self.labels = torch.tensor(labels, dtype=torch.float32)\n        \n    def __len__(self):\n        return len(self.text1)\n    \n    def __getitem__(self, idx):\n        text1_sample = self.text1[idx]\n        text2_sample = self.text2[idx]\n        \n        if len(self.labels) > 0:\n            label = self.labels[idx]\n            return text1_sample, text2_sample, label\n        else:\n            return text1_sample, text2_sample\n    \nval_dataset = DuoDataset(resumes_val_text, vac_val_text, labels=labels_val)\ntrain_dataset = DuoDataset(df.iloc[:, 0], df.iloc[:, 1], labels=df.iloc[:, 2])\n\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\nval_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T21:33:34.949893Z","iopub.execute_input":"2024-03-04T21:33:34.950654Z","iopub.status.idle":"2024-03-04T21:33:34.985769Z","shell.execute_reply.started":"2024-03-04T21:33:34.950621Z","shell.execute_reply":"2024-03-04T21:33:34.984666Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Testing metrics first:\n### With threshold = 0.75","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nfrom IPython.display import clear_output\neval_preds, eval_labels = [], []\n\nmodel.to('cuda')\nmodel.eval()\nwith torch.no_grad():\n    for batch in tqdm(val_dataloader):\n        clear_output()\n        texts1, texts2, labels = batch\n        inp1 = tokenizer(texts1, padding=True, truncation=True,\n                        return_tensors='pt').to('cuda')\n        inp2 = tokenizer(texts2, padding=True, truncation=True,\n                        return_tensors='pt').to('cuda')\n        inp1 = {key: val.to('cuda') for key, val in inp1.items()}\n        inp2 = {key: val.to('cuda') for key, val in inp2.items()}\n        \n        out1 = model(**inp1)\n        out2 = model(**inp2)\n            \n        emb1 = mean_pooling(out1, inp1['attention_mask'])\n        emb2 = mean_pooling(out2, inp2['attention_mask'])\n        cos_sim = nn.functional.cosine_similarity(emb1, emb2)\n        preds = (cos_sim > 0.88).int() #ideal ~0.7 in distrib. proportion (W/O FINETUNE)\n        eval_preds.append(preds.cpu().tolist())\n        eval_labels.append(labels.cpu().tolist())","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:49:25.397686Z","iopub.execute_input":"2024-03-04T19:49:25.398491Z","iopub.status.idle":"2024-03-04T19:49:47.255032Z","shell.execute_reply.started":"2024-03-04T19:49:25.398456Z","shell.execute_reply":"2024-03-04T19:49:47.254126Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"100%|██████████| 82/82 [00:21<00:00,  3.76it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_preds = np.array(eval_preds).reshape(-1, 1)\neval_labels = np.array(eval_labels).reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:49:52.141789Z","iopub.execute_input":"2024-03-04T19:49:52.142531Z","iopub.status.idle":"2024-03-04T19:49:52.147695Z","shell.execute_reply.started":"2024-03-04T19:49:52.142497Z","shell.execute_reply":"2024-03-04T19:49:52.146786Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom collections import Counter\n\nCounter(eval_preds.flatten().tolist()), Counter(eval_labels.flatten().tolist())","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:49:54.376548Z","iopub.execute_input":"2024-03-04T19:49:54.376918Z","iopub.status.idle":"2024-03-04T19:49:54.384333Z","shell.execute_reply.started":"2024-03-04T19:49:54.376891Z","shell.execute_reply":"2024-03-04T19:49:54.383359Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(Counter({0: 512, 1: 144}), Counter({0.0: 463, 1.0: 193}))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(eval_labels.flatten().tolist(), eval_preds.flatten().tolist())) #0.75 THR. NON-TRAINED","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:12:18.536399Z","iopub.execute_input":"2024-03-04T19:12:18.536775Z","iopub.status.idle":"2024-03-04T19:12:18.553510Z","shell.execute_reply.started":"2024-03-04T19:12:18.536745Z","shell.execute_reply":"2024-03-04T19:12:18.552595Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.71      0.87      0.78       463\n         1.0       0.31      0.14      0.19       193\n\n    accuracy                           0.66       656\n   macro avg       0.51      0.51      0.49       656\nweighted avg       0.59      0.66      0.61       656\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(eval_labels.flatten().tolist(), eval_preds.flatten().tolist())) #0.88 THR. AFTER 1 EPOCH (THRESHOLD UP) at margin = 2","metadata":{"execution":{"iopub.status.busy":"2024-03-04T19:49:59.095006Z","iopub.execute_input":"2024-03-04T19:49:59.095653Z","iopub.status.idle":"2024-03-04T19:49:59.110876Z","shell.execute_reply.started":"2024-03-04T19:49:59.095618Z","shell.execute_reply":"2024-03-04T19:49:59.109836Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         0.0       0.70      0.78      0.74       463\n         1.0       0.28      0.21      0.24       193\n\n    accuracy                           0.61       656\n   macro avg       0.49      0.49      0.49       656\nweighted avg       0.58      0.61      0.59       656\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(eval_labels.flatten().tolist(), eval_preds.flatten().tolist())) #0.88 THR. AFTER 2 EPOCHS (THRESHOLD UP) at margin = 3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0.66 ACCURACY MAX.","metadata":{}},{"cell_type":"markdown","source":"### Acceptable, but we want more.","metadata":{}},{"cell_type":"code","source":"# # #Cleaning cache\n# import gc\n# gc.collect()\n# torch.cuda.empty_cache()\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T20:32:48.058794Z","iopub.execute_input":"2024-03-04T20:32:48.059128Z","iopub.status.idle":"2024-03-04T20:32:48.694533Z","shell.execute_reply.started":"2024-03-04T20:32:48.059103Z","shell.execute_reply":"2024-03-04T20:32:48.693542Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"# TODO: CUSTOM DATASET CLASS","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport time\nfrom IPython.display import clear_output\n\nclass ContrastiveLoss_v1(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss_v1, self).__init__()\n        self.margin = margin\n\n    def forward(self, y1, y2, labels):\n        # euclid\n        euc_dist = nn.functional.pairwise_distance(y1, y2)\n        \n        # calc losses\n        losses = (1 - labels) * torch.pow(euc_dist, 2) + \\\n                 labels * torch.pow(torch.clamp(self.margin - euc_dist, min=0.0), 2)\n                 \n        loss = torch.mean(losses)\n        return loss\n\n\nmodel.to('cuda')\n\nloss_func = ContrastiveLoss_v1()\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\nNUM_EPOCHS = 2 #3\n\nfor epoch in tqdm(range(NUM_EPOCHS)):\n    print(f\"EPOCH {epoch+1}\")\n    model.train()\n    total_loss = 0\n    for step, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\", unit=\"batch\")):\n        optimizer.zero_grad()\n        \n        clear_output(wait=True)\n        texts1, texts2, labels = batch\n        inp1 = tokenizer(texts1, padding=True, truncation=True,\n                        return_tensors='pt').to('cuda')\n        inp2 = tokenizer(texts2, padding=True, truncation=True,\n                        return_tensors='pt').to('cuda')\n        inp1 = {key: val.to('cuda') for key, val in inp1.items()}\n        inp2 = {key: val.to('cuda') for key, val in inp2.items()}\n        \n        out1 = model(**inp1)\n        out2 = model(**inp2)\n            \n        emb1 = mean_pooling(out1, inp1['attention_mask'])\n        emb2 = mean_pooling(out2, inp2['attention_mask'])\n\n        loss = loss_func(emb1.to('cuda'), emb2.to('cuda'), labels.to('cuda'))\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        if step % 100 == 1:\n            print(f\"Step {step}: Loss - {total_loss/step}\")\n        \n    avg_loss = total_loss / len(train_dataloader)\n    print(f\"Training loss: {avg_loss:.4f}\")\n    \n    ###val below\n    \n    model.eval()\n    eval_preds, eval_preds1, eval_preds2 = [], [], []\n    with torch.no_grad():\n        val_loss = 0\n        for step, batch in enumerate(val_dataloader):\n            \n            texts1, texts2, labels = batch\n            inp1 = tokenizer(texts1, padding=True, truncation=True,\n                            return_tensors='pt').to('cuda')\n            inp2 = tokenizer(texts2, padding=True, truncation=True,\n                            return_tensors='pt').to('cuda')\n            inp1 = {key: val.to('cuda') for key, val in inp1.items()}\n            inp2 = {key: val.to('cuda') for key, val in inp2.items()}\n\n            out1 = model(**inp1)\n            out2 = model(**inp2)\n\n            emb1 = mean_pooling(out1, inp1['attention_mask'])\n            emb2 = mean_pooling(out2, inp2['attention_mask'])\n            \n            loss = loss_func(emb1.to('cuda'), emb2.to('cuda'), labels.to('cuda'))\n            val_loss += loss.item()\n            \n            cos_sim = nn.functional.cosine_similarity(emb1, emb2)\n            preds = (cos_sim > 0.65).int()\n            preds1 = (cos_sim > 0.7).int()\n            preds2 = (cos_sim > 0.75).int()\n            eval_preds.append(preds.cpu().tolist())\n            eval_preds1.append(preds1.cpu().tolist())\n            eval_preds2.append(preds2.cpu().tolist())\n            \n    eval_preds = np.array(eval_preds).reshape(-1, 1)\n    eval_preds1 = np.array(eval_preds1).reshape(-1, 1)\n    eval_preds2 = np.array(eval_preds2).reshape(-1, 1)\n    \n    avg_val_loss = val_loss / len(val_dataloader)\n    print(f\"Validation loss: {avg_val_loss:.4f}\\n\")\n    print(\"THRESHOLD 0.65:\\n\", classification_report(eval_labels, eval_preds))\n    print(\"THRESHOLD 0.7:\\n\", classification_report(eval_labels, eval_preds1))\n    print(\"THRESHOLD 0.75:\\n\", classification_report(eval_labels, eval_preds2)) \n    time.sleep(10)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:14:04.602336Z","iopub.execute_input":"2024-03-04T22:14:04.603193Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\nEpoch 1:   0%|          | 8/1985 [00:07<30:26,  1.08batch/s]\u001b[A","output_type":"stream"}]},{"cell_type":"code","source":"print(\"FINE-TUNING DONE\")","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:08:06.405010Z","iopub.status.idle":"2024-03-04T22:08:06.405358Z","shell.execute_reply.started":"2024-03-04T22:08:06.405182Z","shell.execute_reply":"2024-03-04T22:08:06.405196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('MODEL_XLM_v1_3ep_clmrgn1')","metadata":{"execution":{"iopub.status.busy":"2024-03-04T22:08:06.410262Z","iopub.status.idle":"2024-03-04T22:08:06.410657Z","shell.execute_reply.started":"2024-03-04T22:08:06.410457Z","shell.execute_reply":"2024-03-04T22:08:06.410473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}