{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6188b84-fb2d-4952-8655-632880fedea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from scipy.spatial.distance import cosine\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccbea8c-fa14-4b31-b9e5-9d0cceb2c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.json', 'r', encoding='utf-8') as file:\n",
    "    train_data_json = json.load(file)\n",
    "train_data = pd.DataFrame(train_data_json)\n",
    "\n",
    "with open('test_data.json', 'r', encoding='utf-8') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61964206-f26c-4eaa-bbef-2fac6dd9ee0e",
   "metadata": {},
   "source": [
    "Функции в коде ниже принимают на вход или json формат или DataFrame по образу `train_data`. Формат прописан в документации функций."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d39a86-85df-44c7-87a9-d3605fe84b60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# О решении\n",
    "\n",
    "## Идея\n",
    "\n",
    "Известные вакансии можно кластеризовать и для центра каждого кластера сделать отдельный классификатор, подходит ли вакансия. На вход этим классификатором подаётся схожесть между описаниями вакансий и резюме, названий вакансий и описанием резюме и т.д. Поскольку в наших данных всего 29 вакансий, то имеет смысл обучить классификатор под каждую из них без дополнительной кластеризации: она понадобиться при выводе решения в production. \n",
    "\n",
    "Когда приходит новая вакансия, считаются схожести её с известными нам вакансиями, и находятся подходящие классификаторы. Для каждого резюме мы используем обученные классификаторы k ближайших соседей новой вакансии. Ответы усредняются обратно-пропорционально расстоянию до этих объектов. Резюме считаем подходящим, если его score > заданного порога.\n",
    "\n",
    "При этом, кандидатов можно ранжировать по score, чтобы сначала выдавать самых релевантных.\n",
    "\n",
    "\n",
    "<a href=\"https://ibb.co/S0Mfd22\"><img src=\"https://i.ibb.co/pZMhRgg/01-03-2024-08-31-16.png\" alt=\"01-03-2024-08-31-16\" border=\"0\"></a>\n",
    "\n",
    "<a href=\"https://ibb.co/G3N2DFN\"><img src=\"https://i.ibb.co/Vp5SG35/01-03-2024-08-31-30.png\" alt=\"01-03-2024-08-31-30\" border=\"0\"></a>\n",
    "\n",
    "\n",
    "\n",
    "## Преимущества\n",
    "\n",
    "- Модульное решение: можно менять\n",
    "\n",
    "      1. классификаторы,\n",
    "      2. кодировщики текста,\n",
    "      3. модель, находящую ближайших соседей\n",
    "      4. кластеризующую модель\n",
    "- Настраиваемые гиперпараметры:\n",
    "  \n",
    "      1. гиперпараметры классификаторов\n",
    "      2. количество ближайших соседей\n",
    "      3. способ взвешивания scores моделей\n",
    "      4. гиперпараметры кодировщика (к примеру, учитывание контекста)\n",
    "- При условии схожести сферы использования (например, только IT-вакансии) малый размер модели "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1873dd8-6458-4e5e-8c3c-75d12f97a191",
   "metadata": {},
   "source": [
    "# Создание корпуса текстов\n",
    "\n",
    "Нужно создать корпус всех тренировочных текстов для обучения TF-IDF vectorizer. Дополнительно полезно сделать нормализацию и очистку текста, которые не делались в этом варианте кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f098aa4-26a3-461f-bea0-6651fdb5ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего записей в корпусе: 556\n"
     ]
    }
   ],
   "source": [
    "def create_corpus(data):\n",
    "    '''\n",
    "    data: pd.DataFrame\n",
    "    returns\n",
    "    list of descriptions in vacancies and resumes\n",
    "    '''\n",
    "    corpus = []\n",
    "    for vacancy in data.loc[:, 'vacancy']:\n",
    "        if vacancy['description'] != None:\n",
    "            corpus.append(vacancy['description'].strip())\n",
    "\n",
    "        if vacancy['name'] != None:\n",
    "            corpus.append(vacancy['name'].strip())\n",
    "\n",
    "        if vacancy['keywords'] != None:\n",
    "            corpus.append(vacancy['keywords'].strip())\n",
    "\n",
    "    for failed_resume in data.loc[:, 'failed_resumes']:\n",
    "        for item in failed_resume[0]['experienceItem']:\n",
    "            if item['description'] != None:\n",
    "                corpus.append(item['description'].strip())\n",
    "            if item['position'] != None:\n",
    "                corpus.append(item['position'].strip())\n",
    "        \n",
    "        if failed_resume[0]['key_skills'] != None:\n",
    "            corpus.append(failed_resume[0]['key_skills'].strip())\n",
    "\n",
    "    for confirmed_resume in data.loc[: , 'confirmed_resumes']:\n",
    "        for item in confirmed_resume[0]['experienceItem']:\n",
    "            if item['description'] != None:\n",
    "                corpus.append(item['description'].strip())\n",
    "            if item['position'] != None:\n",
    "                corpus.append(item['position'].strip())\n",
    "                \n",
    "        if confirmed_resume[0]['key_skills'] != None:\n",
    "            corpus.append(confirmed_resume[0]['key_skills'].strip())\n",
    "\n",
    "    return corpus\n",
    "    \n",
    "\n",
    "corpus = create_corpus(train_data)\n",
    "print('Всего записей в корпусе:', len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2b68cd-4dcc-420d-ad2c-c1fa75bd8494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на экспериментах выяснилось, что ngram_range = (1,2) \n",
    "# лучше всего подходит для понимания контекста \n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2))\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c23567-3e6e-47bc-825a-890e2b0bf352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 24101 слово в словаре кодификатора\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb2283-d971-4eed-97ba-1b3057aca46c",
   "metadata": {},
   "source": [
    "# Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894f8768-9325-4029-bd95-943c5db37b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculcate_cosine_simularity(sent1, sent2, vectorizer):\n",
    "    '''\n",
    "    sent1, sent2: str to encode\n",
    "    vectorizer: class with transform method\n",
    "\n",
    "    returns \n",
    "    float - cosine simularity\n",
    "    '''\n",
    "    vec1 = vectorizer.transform([sent1, sent2])[0]\n",
    "    vec2 = vectorizer.transform([sent1, sent2])[1]\n",
    "    vec1 = np.array(vec1.todense()).reshape(-1)\n",
    "    vec2 = np.array(vec2.todense()).reshape(-1)\n",
    "\n",
    "    cosine_simularity = 1 - cosine(vec1, vec2)\n",
    "    del vec2, vec1 \n",
    "    return cosine_simularity\n",
    "\n",
    "# эвристическая функция, для полной функциональности \n",
    "# нужно провести анализ, какие вузы более предпочтительны\n",
    "# для каждой вакансии\n",
    "def check_university_level(university):\n",
    "    '''\n",
    "    university: str\n",
    "\n",
    "    returns\n",
    "    int 1 or 0 - is university among best universities \n",
    "    '''\n",
    "    TOP_UNIVERSITIES = ['ВШЭ', 'МГУ', 'МФТИ', \n",
    "                        'МИЭМ', 'Финансовый университет', 'МИСИС']\n",
    "\n",
    "    for top_university in TOP_UNIVERSITIES:\n",
    "        if top_university in university:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7649f73-7214-4dc7-a2bb-2d136b8f6225",
   "metadata": {},
   "source": [
    "Датасет резюме для каждой вакансии создаётся следующим образом:\n",
    "1. Отдельно парсятся тексты описания резюме, должностей, навыков\n",
    "2. Считается косинусная схожесть каждого из текстов с названием вакансии и её описанием\n",
    "3. Добавляются доп. признаки: количество дней работы, возраст, является ли вуз топовым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c265a39-a254-4dd6-8ea6-3316090f4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resume_dataset(data, vectorizer):\n",
    "    '''\n",
    "    data: pd.Series \n",
    "    returns\n",
    "    pd.Dataframe for particular vacancy (n_resumes x n_features)\n",
    "    '''\n",
    "    dataset = pd.DataFrame({})\n",
    "\n",
    "    # rejected resumes\n",
    "    for index, resume in enumerate(data['failed_resumes']):\n",
    "\n",
    "        # age\n",
    "        if resume['birth_date'] != None:\n",
    "            dataset.loc[index, 'age'] = pd.to_datetime('2024-02-28').year - pd.to_datetime(resume['birth_date']).year\n",
    "        else:\n",
    "            dataset.loc[index, 'age'] = None\n",
    "\n",
    "        \n",
    "        # common for vacancy\n",
    "        vacancy_desc = data['vacancy']['description']\n",
    "        if data['vacancy']['keywords'] != None:\n",
    "            vacancy_decs += ' ' +  data['vacancy']['keywords']\n",
    "        vacancy_name = data['vacancy']['name']\n",
    "        \n",
    "            \n",
    "        # skills-decription, skills-name simularity\n",
    "        if resume['key_skills'] != None:\n",
    "            skills = resume['key_skills']\n",
    "\n",
    "            dataset.loc[index, 'skills-description_sim'] = calculcate_cosine_simularity(skills, vacancy_desc, vectorizer)\n",
    "            dataset.loc[index, 'skills-name_sim'] = calculcate_cosine_simularity(skills, vacancy_name, vectorizer)\n",
    "        else:\n",
    "            dataset.loc[index, 'skills-description_sim'] = None\n",
    "            dataset.loc[index, 'skills-name_sim'] = None\n",
    "\n",
    "        # description-description, description-name simularity, days of working experience\n",
    "        desc = ''\n",
    "        num_experience = 0\n",
    "        if 'experienceItem' in resume.keys():\n",
    "            for item in resume['experienceItem']:\n",
    "                if item['description'] != None:\n",
    "                    desc += ' ' + item['description'].strip()\n",
    "                    \n",
    "                    start = pd.to_datetime(item['starts'])\n",
    "                    end = pd.to_datetime(item['ends']) if item['ends'] != None else pd.to_datetime('2024-02-28')\n",
    "                    num_experience += (end - start).days\n",
    "    \n",
    "            dataset.loc[index, 'description-description_sim'] = calculcate_cosine_simularity(desc, vacancy_desc, vectorizer)\n",
    "            dataset.loc[index, 'description-name_sim'] = calculcate_cosine_simularity(desc, vacancy_name, vectorizer)\n",
    "            dataset.loc[index, 'num_experience'] = num_experience\n",
    "        else:\n",
    "            dataset.loc[index, 'description-description_sim'] = None\n",
    "            dataset.loc[index, 'description-name_sim'] = None\n",
    "            dataset.loc[index, 'num_experience'] = None\n",
    "\n",
    "\n",
    "        # name-name, name-description similarity\n",
    "        positions = ''\n",
    "        if 'experienceItem' in resume.keys():\n",
    "            for item in resume['experienceItem']:\n",
    "                if item['position'] != None:\n",
    "                    positions += ' ' + item['position']\n",
    "    \n",
    "            dataset.loc[index, 'name-name_sim'] = calculcate_cosine_simularity(positions, vacancy_name, vectorizer)\n",
    "            dataset.loc[index, 'name-description_sim'] = calculcate_cosine_simularity(positions, vacancy_desc, vectorizer)\n",
    "\n",
    "        else:\n",
    "            dataset.loc[index, 'name-name_sim'] = None\n",
    "            dataset.loc[index, 'name-description_sim'] = None\n",
    "\n",
    "        # education experience (is university among best universities)\n",
    "        top_university = 0\n",
    "        if 'educationItem' in resume.keys():\n",
    "            for item in resume['educationItem']:\n",
    "                if check_university_level(item['organization']):\n",
    "                    top_university = 1            \n",
    "        dataset.loc[index, 'university_level'] = top_university\n",
    "\n",
    "        dataset.loc[index, 'target'] = 0\n",
    "\n",
    "    # confirmed resumes\n",
    "    for index, resume in enumerate(data['confirmed_resumes']):\n",
    "        index += dataset.shape[0] #so that vacancies are not overwritten\n",
    "\n",
    "        # age\n",
    "        if resume['birth_date'] != None:\n",
    "            dataset.loc[index, 'age'] = pd.to_datetime('2024-02-28').year - pd.to_datetime(resume['birth_date']).year\n",
    "        else:\n",
    "            dataset.loc[index, 'age'] = None\n",
    "\n",
    "        \n",
    "        # common for vacancy\n",
    "        vacancy_desc = data['vacancy']['description']\n",
    "        if data['vacancy']['keywords'] != None:\n",
    "            vacancy_decs += ' ' +  data['vacancy']['keywords']\n",
    "        vacancy_name = data['vacancy']['name']\n",
    "        \n",
    "            \n",
    "        # skills-decription, skills-name simularity\n",
    "        if resume['key_skills'] != None:\n",
    "            skills = resume['key_skills']\n",
    "\n",
    "            dataset.loc[index, 'skills-description_sim'] = calculcate_cosine_simularity(skills, vacancy_desc, vectorizer)\n",
    "            dataset.loc[index, 'skills-name_sim'] = calculcate_cosine_simularity(skills, vacancy_name, vectorizer)\n",
    "        else:\n",
    "            dataset.loc[index, 'skills-description_sim'] = None\n",
    "            dataset.loc[index, 'skills-name_sim'] = None\n",
    "\n",
    "        # description-description, description-name simularity\n",
    "        desc = ''\n",
    "        num_experience = 0\n",
    "        if 'experienceItem' in resume.keys():\n",
    "            for item in resume['experienceItem']:\n",
    "                if item['description'] != None:\n",
    "                    desc += ' ' + item['description'].strip()\n",
    "                    \n",
    "                    start = pd.to_datetime(item['starts'])\n",
    "                    end = pd.to_datetime(item['ends']) if item['ends'] != None else pd.to_datetime('2024-02-28')\n",
    "                    num_experience += (end - start).days\n",
    "    \n",
    "            dataset.loc[index, 'description-description_sim'] = calculcate_cosine_simularity(desc, vacancy_desc, vectorizer)\n",
    "            dataset.loc[index, 'description-name_sim'] = calculcate_cosine_simularity(desc, vacancy_name, vectorizer)\n",
    "            dataset.loc[index, 'num_experience'] = num_experience\n",
    "        else:\n",
    "            dataset.loc[index, 'description-description_sim'] = None\n",
    "            dataset.loc[index, 'description-name_sim'] = None\n",
    "            dataset.loc[index, 'num_experience'] = None\n",
    "            \n",
    "\n",
    "\n",
    "        # name-name, name-description similarity\n",
    "        positions = ''\n",
    "        if 'experienceItem' in resume.keys():\n",
    "            for item in resume['experienceItem']:\n",
    "                if item['position'] != None:\n",
    "                    positions += ' ' + item['position']\n",
    "    \n",
    "            dataset.loc[index, 'name-name_sim'] = calculcate_cosine_simularity(positions, vacancy_name, vectorizer)\n",
    "            dataset.loc[index, 'name-description_sim'] = calculcate_cosine_simularity(positions, vacancy_desc, vectorizer)\n",
    "\n",
    "        else:\n",
    "            dataset.loc[index, 'name-name_sim'] = None\n",
    "            dataset.loc[index, 'name-description_sim'] = None\n",
    "            \n",
    "\n",
    "        # education experience (is university among best universities)\n",
    "        top_university = 0\n",
    "        if 'educationItem' in resume.keys():\n",
    "            for item in resume['educationItem']:\n",
    "                if check_university_level(item['organization']):\n",
    "                    top_university = 1 \n",
    "        dataset.loc[index, 'university_level'] = top_university\n",
    "        \n",
    "        dataset.loc[index, 'target'] = 1\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62040986-244a-4a83-8064-1b9e05e64aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>skills-description_sim</th>\n",
       "      <th>skills-name_sim</th>\n",
       "      <th>description-description_sim</th>\n",
       "      <th>description-name_sim</th>\n",
       "      <th>num_experience</th>\n",
       "      <th>name-name_sim</th>\n",
       "      <th>name-description_sim</th>\n",
       "      <th>university_level</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083785</td>\n",
       "      <td>0.083386</td>\n",
       "      <td>953.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>0.064787</td>\n",
       "      <td>0.149975</td>\n",
       "      <td>0.027516</td>\n",
       "      <td>4655.0</td>\n",
       "      <td>0.395897</td>\n",
       "      <td>0.049107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.054423</td>\n",
       "      <td>0.055209</td>\n",
       "      <td>0.088955</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>0.200915</td>\n",
       "      <td>0.042620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.037654</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.079083</td>\n",
       "      <td>0.059952</td>\n",
       "      <td>910.0</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  skills-description_sim  skills-name_sim  description-description_sim  \\\n",
       "0   NaN                     NaN              NaN                     0.083785   \n",
       "1   NaN                     NaN              NaN                     0.009051   \n",
       "2  35.0                0.026395         0.064787                     0.149975   \n",
       "3  33.0                0.054423         0.055209                     0.088955   \n",
       "4  24.0                0.037654         0.061845                     0.079083   \n",
       "\n",
       "   description-name_sim  num_experience  name-name_sim  name-description_sim  \\\n",
       "0              0.083386           953.0       0.000000              0.000000   \n",
       "1              0.000000          2037.0       0.000000              0.000000   \n",
       "2              0.027516          4655.0       0.395897              0.049107   \n",
       "3              0.070518          1153.0       0.200915              0.042620   \n",
       "4              0.059952           910.0       0.136400              0.053961   \n",
       "\n",
       "   university_level  target  \n",
       "0               0.0     0.0  \n",
       "1               0.0     0.0  \n",
       "2               0.0     0.0  \n",
       "3               0.0     0.0  \n",
       "4               0.0     0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# как выглядит итоговый датасет для каждой вакансии \n",
    "# (на нём будут обучаться классификаторы) \n",
    "\n",
    "create_resume_dataset(train_data.loc[10], vectorizer).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01425e1d-7962-4c60-8a15-9845c7f738ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fcc0c5037349ff95cfa10c5d041d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# итоговая сборка датасетов для каждой вакансии\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def create_final_dataset(data, vectorizer):\n",
    "    '''\n",
    "    data: pd.DataFrame\n",
    "\n",
    "    returns\n",
    "    dict {vacancy uuid: resume dataset}\n",
    "    '''\n",
    "    dataset = {}\n",
    "    for index in tqdm(range(data.shape[0])):\n",
    "        uuid_vacancy = data.loc[index, 'vacancy']['uuid']\n",
    "        dataset[uuid_vacancy] = create_resume_dataset(data.loc[index], vectorizer)\n",
    "\n",
    "    return dataset\n",
    "final_data = create_final_dataset(train_data, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48976dfa-b7ef-4667-a6d0-a8e2947c897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание датасета вакансий для нахождения ближайших соседей\n",
    "\n",
    "def parse_vacancy(data):\n",
    "    '''\n",
    "    data: dict json-like\n",
    "    '''\n",
    "    dataset = pd.DataFrame({})\n",
    "    for index, item in enumerate(data):\n",
    "        name = item['vacancy']['name']\n",
    "        desc = item['vacancy']['description']\n",
    "        uuid = item['vacancy']['uuid']\n",
    "\n",
    "        dataset.loc[index, ['uuid', 'name', 'description']] = uuid, name, desc\n",
    "        dataset.loc[index, 'uuid'] = uuid\n",
    "\n",
    "    return dataset\n",
    "        \n",
    "vacancy_dataset = parse_vacancy(train_data_json)\n",
    "vacancy_dataset.to_csv('vacancy_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1afed29f-d059-4dcd-9e84-9ef56e342005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>779f3a59-206a-3241-adc4-d7db504f960b</td>\n",
       "      <td>Java разработчик команда Инвестиции</td>\n",
       "      <td>Описание Мы расширяем команды и ищем разработ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7a4813fc-43bc-3896-a607-4c8682b01002</td>\n",
       "      <td>Системный аналитик</td>\n",
       "      <td>Уровень: СА уровня Middle+/Senior от 3х лет В...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c03085c3-9b1e-3564-bb1e-59aa72e5fbca</td>\n",
       "      <td>Ведущий/ Главный аналитик DWH</td>\n",
       "      <td>Желательно знания Oracle   сегодня — не прост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a8dd83c3-178d-3c70-90c2-7c3648f6b96a</td>\n",
       "      <td>Системный аналитик</td>\n",
       "      <td>Знания и опыт • Умение управлять ожиданиями з...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9d98eba0-13bb-38d3-b742-4fd445954b3d</td>\n",
       "      <td>Product manager</td>\n",
       "      <td>- Продактов в компании сейчас порядка 250, вс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid                                 name  \\\n",
       "0  779f3a59-206a-3241-adc4-d7db504f960b  Java разработчик команда Инвестиции   \n",
       "1  7a4813fc-43bc-3896-a607-4c8682b01002                   Системный аналитик   \n",
       "2  c03085c3-9b1e-3564-bb1e-59aa72e5fbca        Ведущий/ Главный аналитик DWH   \n",
       "3  a8dd83c3-178d-3c70-90c2-7c3648f6b96a                   Системный аналитик   \n",
       "4  9d98eba0-13bb-38d3-b742-4fd445954b3d                      Product manager   \n",
       "\n",
       "                                         description  \n",
       "0   Описание Мы расширяем команды и ищем разработ...  \n",
       "1   Уровень: СА уровня Middle+/Senior от 3х лет В...  \n",
       "2   Желательно знания Oracle   сегодня — не прост...  \n",
       "3   Знания и опыт • Умение управлять ожиданиями з...  \n",
       "4   - Продактов в компании сейчас порядка 250, вс...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancy_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea7166-75c6-45ca-8113-14a74742dd87",
   "metadata": {},
   "source": [
    "# Обучаем классификаторы\n",
    "\n",
    "В качестве классификатора мы выбрали Catboost по результатам экспериментов. Также пытались заменить в нём стандартную кросс-энтропию на [FocalLoss](https://paperswithcode.com/method/focal-loss), который лучше работает с дисбалансом классов, но этот с этим лоссом итоговая модель не показала результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f15a660-b88c-4487-94b0-d61d828fb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d48c002-f5a6-496f-8da3-08ef38bd3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossObjective(object):\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        # approxes, targets, weights are indexed containers of floats\n",
    "        # (containers with only __len__ and __getitem__ defined).\n",
    "        # weights parameter can be None.\n",
    "        # Returns list of pairs (der1, der2)\n",
    "        gamma = 0.8\n",
    "        # alpha = 1.\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "        \n",
    "        exponents = []\n",
    "        for index in xrange(len(approxes)):\n",
    "            exponents.append(math.exp(approxes[index]))\n",
    "\n",
    "        result = []\n",
    "        for index in xrange(len(targets)):\n",
    "            p = exponents[index] / (1 + exponents[index])\n",
    "\n",
    "            if targets[index] > 0.0:\n",
    "                der1 = -((1-p)**(gamma-1))*(gamma * math.log(p) * p + p - 1)/p\n",
    "                der2 = gamma*((1-p)**gamma)*((gamma*p-1)*math.log(p)+2*(p-1))\n",
    "            else:\n",
    "                der1 = (p**(gamma-1)) * (gamma * math.log(1 - p) - p)/(1 - p)\n",
    "                der2 = p**(gamma-2)*((p*(2*gamma*(p-1)-p))/(p-1)**2 + (gamma-1)*gamma*math.log(1 - p))\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "652b7f59-f70c-40d3-950c-89e098c0c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.75      0.86         4\n",
      "         1.0       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.88      0.88      0.86         7\n",
      "weighted avg       0.89      0.86      0.86         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# эксперименты с FocalLoss\n",
    "uuid = np.random.choice(vacancy_dataset['uuid'],1)[0]\n",
    "df = final_data[uuid]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), \n",
    "                                                    df['target'], test_size = 0.3, shuffle = True)\n",
    "clf = CatBoostClassifier(silent=True, loss_function = FocalLossObjective(), \n",
    "                         eval_metric = 'Precision').fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5ca93ce-d369-461f-a2d9-e3be6ca74c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a367524178934fe4ba4692c05e4452f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {'silent':True, 'loss_function': FocalLossObjective(), 'eval_metric': 'Precision'}\n",
    "#params = {'silent' : True}\n",
    "model = CatBoostClassifier\n",
    "\n",
    "def train_models(model, params):\n",
    "    models = {}\n",
    "    for uuid in tqdm(vacancy_dataset['uuid']):\n",
    "        df = final_data[uuid]\n",
    "        \n",
    "        clf = model(**params)\n",
    "        clf.fit(df.drop('target', axis = 1), df['target'])\n",
    "    \n",
    "        models[uuid] = clf\n",
    "    return models\n",
    "\n",
    "models = train_models(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a812cba-78a5-4bdc-992e-15eaf0791430",
   "metadata": {},
   "source": [
    "# Поиск ближайших вакансий к данной\n",
    "\n",
    "В этом разделе определяется функция, которая по заданной вакансии ищет похожие к ней на основе сконкатенированного вектора [название вакансии; текст описания вакансии]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f850c2d4-d633-4e02-9209-ec0effe6b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text_vacancy_representation(vacancy_dataset):\n",
    "    '''\n",
    "    vacancy_dataset: pd.DataFrame\n",
    "\n",
    "    returns\n",
    "    pd.DataFrame with concated names and vacancy description\n",
    "    '''\n",
    "    \n",
    "    vacancy_dataset['full_text'] = vacancy_dataset.apply(\n",
    "                                                        lambda x: x['name'] + ' ' \\\n",
    "                                                        + x['description'], axis = 1)\n",
    "\n",
    "    return vacancy_dataset[['uuid','full_text']]\n",
    "\n",
    "def find_knearest_neighbours(vacancy, vacancy_dataset, vectorizer, k = 2):\n",
    "    '''\n",
    "    vacancy: dict-like vacancy\n",
    "    vacancy_dataset: pd.DataFrame\n",
    "    vectorizer: transformer class with transform method\n",
    "    k: int - number of nearest neighbours\n",
    "\n",
    "    returns \n",
    "    pd.DataFrame with [uuid, sim_score] columns \n",
    "    '''\n",
    "    # parsing full vacancy text\n",
    "    vacancy_text = ''\n",
    "    \n",
    "    vacancy_text += ' ' + vacancy['name']\n",
    "    \n",
    "    if vacancy['keywords'] != None:\n",
    "        vacancy_text += ' ' + vacancy['keywords']\n",
    "\n",
    "    vacancy_text += ' ' + vacancy['description']\n",
    "    \n",
    "    vacancy_dataset_transformed = get_full_text_vacancy_representation(vacancy_dataset)\n",
    "    vacancy_dataset_transformed['sim_score'] = vacancy_dataset_transformed['full_text'] \\\n",
    "                                                .apply(calculcate_cosine_simularity, args = (vacancy_text, vectorizer))\n",
    "\n",
    "    knearest_neighbours = vacancy_dataset_transformed.sort_values(by = 'sim_score', ascending = False) \\\n",
    "                                                        .head(k)[['uuid', 'sim_score']]\n",
    "    return knearest_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45d65ba7-e4b8-4155-b092-1435a703a134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aecfdaf6-e12c-3309-8f1b-157028ef63d5</td>\n",
       "      <td>0.208840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b2315867-73a2-3d43-acac-cbb92bd793b3</td>\n",
       "      <td>0.202114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uuid  sim_score\n",
       "26  aecfdaf6-e12c-3309-8f1b-157028ef63d5   0.208840\n",
       "24  b2315867-73a2-3d43-acac-cbb92bd793b3   0.202114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knearest_neighbours = find_knearest_neighbours(test_data['vacancy'], vacancy_dataset, vectorizer, k = 2)\n",
    "knearest_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "539adbd5-bbbd-4194-ba3c-5e3a8af1beab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aecfdaf6-e12c-3309-8f1b-157028ef63d5</td>\n",
       "      <td>Java-разработчик</td>\n",
       "      <td>Опыт работы с java от 3 лет Уверенные знания ...</td>\n",
       "      <td>Java-разработчик  Опыт работы с java от 3 лет ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uuid              name  \\\n",
       "26  aecfdaf6-e12c-3309-8f1b-157028ef63d5  Java-разработчик   \n",
       "\n",
       "                                          description  \\\n",
       "26   Опыт работы с java от 3 лет Уверенные знания ...   \n",
       "\n",
       "                                            full_text  \n",
       "26  Java-разработчик  Опыт работы с java от 3 лет ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# одна из найденных похожих вакансий \n",
    "vacancy_dataset[vacancy_dataset['uuid'] == 'aecfdaf6-e12c-3309-8f1b-157028ef63d5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74a246ab-2ee9-49ad-908a-e0f4974e1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataset(data):\n",
    "    '''\n",
    "    data: dict json-like\n",
    "    '''\n",
    "\n",
    "    dataset = pd.DataFrame({})\n",
    "    for index, resume in enumerate(data['resumes']):\n",
    "\n",
    "        # age\n",
    "        if resume['birth_date'] != None:\n",
    "            dataset.loc[index, 'age'] = pd.to_datetime('2024-02-28').year - pd.to_datetime(resume['birth_date']).year\n",
    "        else:\n",
    "            dataset.loc[index, 'age'] = None\n",
    "\n",
    "        \n",
    "        # common for vacancy\n",
    "        vacancy_desc = data['vacancy']['description']\n",
    "        if data['vacancy']['keywords'] != None:\n",
    "            vacancy_desc += ' ' +  data['vacancy']['keywords']\n",
    "        vacancy_name = data['vacancy']['name']\n",
    "        \n",
    "            \n",
    "        # skills-decription, skills-name simularity\n",
    "        if resume['key_skills'] != None:\n",
    "            skills = resume['key_skills']\n",
    "\n",
    "            dataset.loc[index, 'skills-description_sim'] = calculcate_cosine_simularity(skills, vacancy_desc, vectorizer)\n",
    "            dataset.loc[index, 'skills-name_sim'] = calculcate_cosine_simularity(skills, vacancy_name, vectorizer)\n",
    "        else:\n",
    "            dataset.loc[index, 'skills-description_sim'] = None\n",
    "            dataset.loc[index, 'skills-name_sim'] = None\n",
    "\n",
    "        # description-description, description-name simularity, days of working experience\n",
    "        desc = ''\n",
    "        num_experience = 0\n",
    "        if 'experienceItem' in resume.keys():\n",
    "            for item in resume['experienceItem']:\n",
    "                if item['description'] != None:\n",
    "                    desc += ' ' + item['description'].strip()\n",
    "                    \n",
    "                    start = pd.to_datetime(item['starts'])\n",
    "                    end = pd.to_datetime(item['ends']) if item['ends'] != None else pd.to_datetime('2024-02-28')\n",
    "                    num_experience += (end - start).days\n",
    "    \n",
    "            dataset.loc[index, 'description-description_sim'] = calculcate_cosine_simularity(desc, vacancy_desc, vectorizer)\n",
    "            dataset.loc[index, 'description-name_sim'] = calculcate_cosine_simularity(desc, vacancy_name, vectorizer)\n",
    "            dataset.loc[index, 'num_experience'] = num_experience\n",
    "        else:\n",
    "            dataset.loc[index, 'description-description_sim'] = None\n",
    "            dataset.loc[index, 'description-name_sim'] = None\n",
    "            dataset.loc[index, 'num_experience'] = None\n",
    "\n",
    "\n",
    "        # name-name, name-description similarity\n",
    "        positions = ''\n",
    "        if 'experienceItem' in resume.keys():\n",
    "            for item in resume['experienceItem']:\n",
    "                if item['position'] != None:\n",
    "                    positions += ' ' + item['position']\n",
    "    \n",
    "            dataset.loc[index, 'name-name_sim'] = calculcate_cosine_simularity(positions, vacancy_name, vectorizer)\n",
    "            dataset.loc[index, 'name-description_sim'] = calculcate_cosine_simularity(positions, vacancy_desc, vectorizer)\n",
    "\n",
    "        else:\n",
    "            dataset.loc[index, 'name-name_sim'] = None\n",
    "            dataset.loc[index, 'name-description_sim'] = None\n",
    "\n",
    "        # education experience (is university among best universities)\n",
    "        top_university = 0\n",
    "        if 'educationItem' in resume.keys():\n",
    "            for item in resume['educationItem']:\n",
    "                if check_university_level(item['organization']):\n",
    "                    top_university = 1            \n",
    "        dataset.loc[index, 'university_level'] = top_university\n",
    "\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e569a3a6-abd4-4563-9171-1ca63ce60dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>skills-description_sim</th>\n",
       "      <th>skills-name_sim</th>\n",
       "      <th>description-description_sim</th>\n",
       "      <th>description-name_sim</th>\n",
       "      <th>num_experience</th>\n",
       "      <th>name-name_sim</th>\n",
       "      <th>name-description_sim</th>\n",
       "      <th>university_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.063237</td>\n",
       "      <td>0.047638</td>\n",
       "      <td>0.170534</td>\n",
       "      <td>0.054532</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>0.550199</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.082959</td>\n",
       "      <td>0.068509</td>\n",
       "      <td>0.117585</td>\n",
       "      <td>0.033226</td>\n",
       "      <td>4233.0</td>\n",
       "      <td>0.118201</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.049972</td>\n",
       "      <td>0.051185</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>0.457527</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>0.074611</td>\n",
       "      <td>0.096917</td>\n",
       "      <td>0.046442</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>0.666033</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190342</td>\n",
       "      <td>0.052352</td>\n",
       "      <td>3498.0</td>\n",
       "      <td>0.203875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  skills-description_sim  skills-name_sim  description-description_sim  \\\n",
       "0  33.0                0.063237         0.047638                     0.170534   \n",
       "1  34.0                0.082959         0.068509                     0.117585   \n",
       "2  34.0                0.033481         0.050157                     0.049972   \n",
       "3  34.0                0.029594         0.074611                     0.096917   \n",
       "4  29.0                     NaN              NaN                     0.190342   \n",
       "\n",
       "   description-name_sim  num_experience  name-name_sim  name-description_sim  \\\n",
       "0              0.054532          1611.0       0.550199              0.018682   \n",
       "1              0.033226          4233.0       0.118201              0.015664   \n",
       "2              0.051185          1826.0       0.457527              0.019084   \n",
       "3              0.046442          3632.0       0.666033              0.014082   \n",
       "4              0.052352          3498.0       0.203875              0.000000   \n",
       "\n",
       "   university_level  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = create_test_dataset(test_data)\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad59b70-33a3-4caa-90f0-4571a7e5dfdc",
   "metadata": {},
   "source": [
    "# Формируем итоговое предсказание "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e45cc27f-07f0-4da8-ac3c-8b2d40526988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_prediction(test_data, models, knearest_neighbours, threshold = 0.5, df_resume = None):\n",
    "    if df_resume is None: # for validation part\n",
    "        df_resume =  create_test_dataset(test_data)\n",
    "    \n",
    "    # forming probs\n",
    "    probs = np.zeros((knearest_neighbours.shape[0], df_resume.shape[0]))\n",
    "    for i, uuid in enumerate(knearest_neighbours['uuid']):\n",
    "        probs[i, :] += models[uuid].predict_proba(df_resume)[:, 1]\n",
    "\n",
    "    # scaling probs to distance\n",
    "    sim_scores = knearest_neighbours.loc[:,'sim_score'].to_numpy()**-1\n",
    "    sim_scores /= sim_scores.sum()\n",
    "    final_scores = (sim_scores.reshape(len(sim_scores), 1) * probs).sum(0)\n",
    "\n",
    "    indx = np.where(final_scores >= threshold)[0]\n",
    "    uuids_prediction = []\n",
    "\n",
    "    for item in np.array(test_data['resumes'])[list(indx)]:\n",
    "        uuids_prediction.append(item['uuid'])\n",
    "\n",
    "    return uuids_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a84efd-eb90-493a-b0ae-29300a70a5ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9a9c3ff1-49f8-30dd-a294-e56fc60cae64',\n",
       " '6f48fd66-a056-3172-af60-632f22844934',\n",
       " 'd9fffe2b-cba9-3ff2-bd47-b8bfc48cbe89']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_prediction(test_data, models, knearest_neighbours, threshold = 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7be5e-b4f4-4b29-be3b-10af2c11df7f",
   "metadata": {},
   "source": [
    "# Валидация\n",
    "\n",
    "Валидация - тонкое место этой модели, с ней есть несколько проблем. Во-первых, базовые классификаторы склонны отдавать предпочтения мажорному классу и выставлять низкий score (<0.5), поэтому необходимо подбирать порог.\n",
    "\n",
    "Важной метрикой при подборке количества соседей (k) и порога (threshold) была accuracy, посчитанная как процент угаданных резюме среди общего пулла подходящих резюме. Естественно, это не единственный показатель, ведь достаточно поставить `threshold = 0`, чтобы максимизировать этот показатель в 1. \n",
    "\n",
    "Эвристическими соображениями были выбраны `k=4, threshold = 0.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b6013dd-1c26-4c7e-b816-98bcb7c7e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_vacancy(train_data_json, n = 1):\n",
    "    '''\n",
    "    Randomly choose one vacancy from dataset\n",
    "    \n",
    "    train_data_json: dict json-like\n",
    "    returns \n",
    "    index: int\n",
    "    val_data: dict with vacancy and resumes for vacancy\n",
    "    \n",
    "    '''\n",
    "    indx = np.random.choice(range(len(train_data_json)), n)\n",
    "\n",
    "    val_data = np.array(train_data_json)[indx][0]\n",
    "    val_data['resumes'] = val_data['confirmed_resumes'] + val_data['failed_resumes']\n",
    "    return indx[0], val_data\n",
    "\n",
    "def check_accuracy(indx, train_data_json, predictions):\n",
    "    '''\n",
    "    indx: int\n",
    "    train_data_json: dict json-like\n",
    "    predictions: str[] - list of uuids\n",
    "\n",
    "    returns\n",
    "    int - percentage of right predictions\n",
    "    '''\n",
    "    real_uuids = []\n",
    "    for item in train_data_json[indx]['confirmed_resumes']:\n",
    "        real_uuids.append(item['uuid'])\n",
    "\n",
    "    predictions, real_uuids = set(predictions), set(real_uuids)\n",
    "    accuracy = len(real_uuids.intersection(predictions)) / len(real_uuids)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def make_classification_report(indx, train_data_json, predictions):\n",
    "    '''\n",
    "    indx: int\n",
    "    train_data_json: dict json-like\n",
    "    predictions: str[] - list of uuids\n",
    "\n",
    "    returns\n",
    "    classification report in sklearn format\n",
    "    '''\n",
    "    \n",
    "    resumes = pd.DataFrame({})\n",
    "    for item in train_data_json[indx]['confirmed_resumes']:\n",
    "        resumes.loc[item['uuid'], 'target'] = 1\n",
    "    for item in train_data_json[indx]['failed_resumes']:\n",
    "        resumes.loc[item['uuid'], 'target'] = 0\n",
    "    resumes['predicted_label'] = resumes.apply(lambda x: 1 if x.index.values in predictions else 0, axis = 1)\n",
    "\n",
    "    return classification_report(resumes['target'], resumes['predicted_label'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "655476f0-3b42-4281-b80f-0a1e13b40147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_params(k_list, threshold_list, n = 5):\n",
    "    '''\n",
    "    k_list: int[]  \n",
    "    threshold_list: int[]\n",
    "    n: int\n",
    "\n",
    "    returns\n",
    "    dict with mean accuracy for each k and threshold\n",
    "    '''\n",
    "    final_accuracies = defaultdict(lambda: {})\n",
    "\n",
    "    for k in tqdm(k_list):\n",
    "        for threshold in threshold_list:\n",
    "\n",
    "            mean_score = 0\n",
    "            for _ in range(n):\n",
    "    \n",
    "                indx, val_data = get_validation_vacancy(train_data_json, n = 1)\n",
    "                train_data_transformed_json = train_data_json[:indx] + train_data_json[indx+1:]\n",
    "                \n",
    "                train_dataset_transformed = pd.DataFrame(train_data_transformed_json)\n",
    "                \n",
    "                # dataset of resumes for deleted vacancy\n",
    "                eval_dataset = create_resume_dataset(val_data, vectorizer)\n",
    "                \n",
    "                # dataset of vacancies without evaluated one\n",
    "                df_vac = parse_vacancy(train_data_transformed_json)\n",
    "                                \n",
    "                knearest_neighbours = find_knearest_neighbours(val_data['vacancy'], df_vac, vectorizer, k = k)\n",
    "            \n",
    "                predictions = get_final_prediction(val_data, models, knearest_neighbours, threshold = threshold, \n",
    "                                                   df_resume = eval_dataset)\n",
    "                score = check_accuracy(indx, train_data_json, predictions)\n",
    "                mean_score += score / n\n",
    "                                    \n",
    "            \n",
    "            final_accuracies[k][threshold] = mean_score\n",
    "\n",
    "    return final_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f340b4e-ff57-4a46-a531-8e754bf8b031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38400ebc5e9f4cdabad0d19b207ba688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.find_best_params.<locals>.<lambda>()>,\n",
       "            {2: {0.2: 0.8722222222222222,\n",
       "              0.3: 0.6366666666666667,\n",
       "              0.4: 0.7273913043478262},\n",
       "             3: {0.2: 0.9538461538461539,\n",
       "              0.3: 0.7057142857142856,\n",
       "              0.4: 0.21666666666666667},\n",
       "             4: {0.2: 0.9777777777777776,\n",
       "              0.3: 0.45,\n",
       "              0.4: 0.24239130434782608}})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catboost with focal loss + n_grams = (1,2)\n",
    "k_list, threshold_list = [2,3,4], [0.2, 0.3, 0.4]\n",
    "final_accuracies = find_best_params(k_list, threshold_list)\n",
    "final_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2961dddf-79c2-4bad-8ba7-6b850a5e23df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.find_best_params.<locals>.<lambda>()>,\n",
       "            {2: {0.2: 0.728623188405797, 0.3: 0.7927536231884058, 0.4: 0.5},\n",
       "             3: {0.2: 1.0, 0.3: 0.6936507936507936, 0.4: 0.38666666666666666},\n",
       "             4: {0.2: 1.0, 0.3: 0.8857142857142859, 0.4: 0.2658385093167702}})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catboost + n_grams = (1,2), mean by five evaluations\n",
    "final_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5c987155-cd56-4735-a60a-bf3efc2c4d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.find_best_params.<locals>.<lambda>()>,\n",
       "            {1: {0.1: 1.0,\n",
       "              0.2: 0.75,\n",
       "              0.3: 0.0,\n",
       "              0.4: 0.2222222222222222,\n",
       "              0.5: 0.0},\n",
       "             2: {0.1: 1.0,\n",
       "              0.2: 1.0,\n",
       "              0.3: 0.8333333333333334,\n",
       "              0.4: 1.0,\n",
       "              0.5: 0.0},\n",
       "             3: {0.1: 1.0,\n",
       "              0.2: 1.0,\n",
       "              0.3: 0.125,\n",
       "              0.4: 0.2222222222222222,\n",
       "              0.5: 0.0},\n",
       "             4: {0.1: 1.0, 0.2: 1.0, 0.3: 1.0, 0.4: 0.75, 0.5: 0.0},\n",
       "             5: {0.1: 1.0,\n",
       "              0.2: 1.0,\n",
       "              0.3: 0.5,\n",
       "              0.4: 0.14285714285714285,\n",
       "              0.5: 0.0}})"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catboost + n_grams = (1,2), one evaluation\n",
    "final_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "134923f1-c9ad-4bb7-a7a8-8bcf160064c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.find_best_params.<locals>.<lambda>()>,\n",
       "            {1: {0.1: 1.0,\n",
       "              0.2: 0.9090909090909091,\n",
       "              0.3: 0.0,\n",
       "              0.4: 0.0,\n",
       "              0.5: 0.2727272727272727},\n",
       "             2: {0.1: 1.0, 0.2: 1.0, 0.3: 1.0, 0.4: 0.7, 0.5: 0.0},\n",
       "             3: {0.1: 1.0,\n",
       "              0.2: 1.0,\n",
       "              0.3: 0.6666666666666666,\n",
       "              0.4: 0.0,\n",
       "              0.5: 0.08333333333333333},\n",
       "             4: {0.1: 1.0,\n",
       "              0.2: 1.0,\n",
       "              0.3: 1.0,\n",
       "              0.4: 0.6,\n",
       "              0.5: 0.3333333333333333},\n",
       "             5: {0.1: 1.0, 0.2: 1.0, 0.3: 1.0, 0.4: 1.0, 0.5: 0.0}})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catboost + n_grams = (1,1), one_evaluation\n",
    "final_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ceda7-51a9-4790-8f76-5c5ae942d6bf",
   "metadata": {},
   "source": [
    "# Предсказания для ансамбля\n",
    "\n",
    "Здесь подсчитываются scores для каждого кандидата из тестового датасета, и формируется датафрейм, содержащий `uuid` резюме и его `resume`.\n",
    "\n",
    "В итоге модель не использовалась в ансамбле, но сам датасет полезен для оценки алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c96b22ff-0d56-41b9-823c-ef6b433854bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_prediction_score(test_data, models, knearest_neighbours, df_resume = None):\n",
    "    if df_resume is None: # for validation part\n",
    "        df_resume =  create_test_dataset(test_data)\n",
    "    \n",
    "    # forming probs\n",
    "    probs = np.zeros((knearest_neighbours.shape[0], df_resume.shape[0]))\n",
    "    for i, uuid in enumerate(knearest_neighbours['uuid']):\n",
    "        probs[i, :] += models[uuid].predict_proba(df_resume)[:, 1]\n",
    "\n",
    "    # scaling probs to distance\n",
    "    sim_scores = knearest_neighbours.loc[:,'sim_score'].to_numpy()**-1\n",
    "    sim_scores /= sim_scores.sum()\n",
    "    final_scores = (sim_scores.reshape(len(sim_scores), 1) * probs).sum(0)\n",
    "\n",
    "    final_df = pd.DataFrame({})\n",
    "\n",
    "    for index, item in enumerate(np.array(test_data['resumes'])):\n",
    "        final_df.loc[index, 'uuid'] = item['uuid']\n",
    "        final_df.loc[index, 'score'] = final_scores[index]\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c9eaf72-e043-423b-86a9-a179b02612ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "knearest_neighbours = find_knearest_neighbours(test_data['vacancy'], vacancy_dataset, vectorizer, k = 4)\n",
    "final_predictions = get_final_prediction_score(test_data, models, knearest_neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38272fc4-1931-4095-bd40-b4ce637a6b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17 подходящих резюме с заданным порогом\n",
    "len(final_predictions[final_predictions['score'] >= 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6a5ad575-ae03-48d5-9c32-db122031ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions.to_csv('final_score_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
